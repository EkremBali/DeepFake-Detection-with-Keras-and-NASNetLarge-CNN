{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8124,
     "status": "ok",
     "timestamp": 1658492567486,
     "user": {
      "displayName": "Ekrem Balı",
      "userId": "17683390588978915548"
     },
     "user_tz": -180
    },
    "id": "5Pmp640L7T7a"
   },
   "outputs": [],
   "source": [
    "#Gerekli kütüphanelerin import edilmesi.Gereksiz kütüphaneler de bulunuyor olabilir. Silebilirsiniz.\n",
    "\n",
    "import json\n",
    "import os\n",
    "from distutils.dir_util import copy_tree\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import applications\n",
    "from keras.applications.nasnet import NASNetLarge\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/CDv2\\train\n",
      "dataset/CDv2\\val\n"
     ]
    }
   ],
   "source": [
    "#NASNetLarge CNN mimarisi girdi olarak 331x331 veri almaktadır. Batch size donanımınız yeterli ise arttırılabilir.\n",
    "\n",
    "input_size = 331\n",
    "batch_size_num = 2\n",
    "\n",
    "dataset_path = \"dataset/CDv2_Ornek\"\n",
    "train_path = os.path.join(dataset_path, 'train')\n",
    "val_path = os.path.join(dataset_path, 'val')\n",
    "\n",
    "print(train_path)\n",
    "print(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37968 images belonging to 2 classes.\n",
      "Found 5473 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#ImageDataGenerator ile veriler dosyadan çekilirken gerçekleştirilecek augmentation yöntemleri ve parametreleri belirleniyor.\n",
    "#Bu işlem sayesinde hem veriler eğitime hazır hale geliyor hem de overfitting'den kaçınılıyor.\n",
    "#Validation verileine bu augmentation işlemleri uygulanmıyor.\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,    \n",
    "    rotation_range = 45,\n",
    "    width_shift_range = 0.3,\n",
    "    height_shift_range = 0.3,\n",
    "    shear_range = 0.3,\n",
    "    zoom_range = 0.3,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory = train_path,\n",
    "    target_size = (input_size, input_size),\n",
    "    color_mode = \"rgb\",\n",
    "    class_mode = \"binary\",\n",
    "    batch_size = batch_size_num,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255 \n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory = val_path,\n",
    "    target_size = (input_size, input_size),\n",
    "    color_mode = \"rgb\",\n",
    "    class_mode = \"binary\",\n",
    "    batch_size = batch_size_num,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1658492222158,
     "user": {
      "displayName": "Ekrem Balı",
      "userId": "17683390588978915548"
     },
     "user_tz": -180
    },
    "id": "gb9SRe6j7fWT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " NASNet (Functional)         (None, 11, 11, 4032)      84916818  \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 487872)            0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 487872)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 487873    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,404,691\n",
      "Trainable params: 85,208,023\n",
      "Non-trainable params: 196,668\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Bu hücrede model hazırlanmaktadır. Öncelikle NASNetLarge modeli import edilmekte. Bu modelin sınıflandırıcı katmanı devre dışı\n",
    "#bırakılmakta ve katmanlar eğitilebilir olarak ayarlanmaktadır. Ardından sınıflandırıcı olarak bir dense katmanı eklenir.\n",
    "#Modele uygun optimizer parametreleri de ayarlandıktan sonra model eğitime hazır hale gelmektedir.\n",
    "\n",
    "from tensorflow.keras.applications.nasnet import NASNetLarge\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "nasnetModel = NASNetLarge(include_top=False, weights='imagenet', input_shape=(331,331,3))\n",
    "nasnetModel.trainable = True\n",
    "model = Sequential()\n",
    "model.add(nasnetModel)\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1658492453875,
     "user": {
      "displayName": "Ekrem Balı",
      "userId": "17683390588978915548"
     },
     "user_tz": -180
    },
    "id": "9Sh60X5f7yts"
   },
   "outputs": [],
   "source": [
    "#EarlyStopping ve ModelCheckpoint callback fonksiyonlarının hazırlanması.\n",
    "\n",
    "checkpoint_filepath = 'tmp_checkpoint'\n",
    "\n",
    "custom_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0,\n",
    "        patience=5,\n",
    "        verbose=0, \n",
    "        mode='auto'\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath = os.path.join(checkpoint_filepath, 'best_model_NAS_CDv2'),\n",
    "        monitor = 'val_loss',\n",
    "        mode = 'min',\n",
    "        verbose = 1,\n",
    "        save_best_only = True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programlar\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "#GPU yetersiz olduğu durumlarda tam güçle çalışmadan eğitimi sürdürmesini sağladı. \n",
    "#Fakat veri kümesi küçük kullanıldığında veya sizin donanımınız yeterli ise bu hücreye gerek yok.\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "error",
     "timestamp": 1658492543026,
     "user": {
      "displayName": "Ekrem Balı",
      "userId": "17683390588978915548"
     },
     "user_tz": -180
    },
    "id": "kcop9Bdo71-C",
    "outputId": "6201ed7c-3698-49dc-d1f4-0d4ed009e4c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "37968/37968 [==============================] - ETA: 0s - loss: 0.5433 - accuracy: 0.7009\n",
      "Epoch 1: val_loss improved from inf to 0.48018, saving model to tmp_checkpoint\\best_model_NAS_CDv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) NASNet_input with unsupported characters which will be renamed to nasnet_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 268). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp_checkpoint\\best_model_NAS_CDv2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp_checkpoint\\best_model_NAS_CDv2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37968/37968 [==============================] - 47513s 1s/step - loss: 0.5433 - accuracy: 0.7009 - val_loss: 0.4802 - val_accuracy: 0.8061\n",
      "Epoch 2/20\n",
      "37968/37968 [==============================] - ETA: 0s - loss: 0.2491 - accuracy: 0.8964\n",
      "Epoch 2: val_loss did not improve from 0.48018\n",
      "37968/37968 [==============================] - 28415s 748ms/step - loss: 0.2491 - accuracy: 0.8964 - val_loss: 1.3922 - val_accuracy: 0.9088\n",
      "Epoch 3/20\n",
      "37968/37968 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.9362\n",
      "Epoch 3: val_loss did not improve from 0.48018\n",
      "37968/37968 [==============================] - 27115s 714ms/step - loss: 0.1648 - accuracy: 0.9362 - val_loss: 1.6073 - val_accuracy: 0.9457\n",
      "Epoch 4/20\n",
      "37968/37968 [==============================] - ETA: 0s - loss: 0.1286 - accuracy: 0.9515\n",
      "Epoch 4: val_loss did not improve from 0.48018\n",
      "37968/37968 [==============================] - 26891s 708ms/step - loss: 0.1286 - accuracy: 0.9515 - val_loss: 3.0201 - val_accuracy: 0.9381\n",
      "Epoch 5/20\n",
      "37968/37968 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.9583\n",
      "Epoch 5: val_loss did not improve from 0.48018\n",
      "37968/37968 [==============================] - 24827s 654ms/step - loss: 0.1110 - accuracy: 0.9583 - val_loss: 22.3180 - val_accuracy: 0.9406\n",
      "Epoch 6/20\n",
      "37968/37968 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9628\n",
      "Epoch 6: val_loss did not improve from 0.48018\n",
      "37968/37968 [==============================] - 24903s 656ms/step - loss: 0.0986 - accuracy: 0.9628 - val_loss: 27.0961 - val_accuracy: 0.9558\n",
      "{'loss': [0.5432671904563904, 0.24911437928676605, 0.16475637257099152, 0.1285976618528366, 0.11095661669969559, 0.09864988923072815], 'accuracy': [0.7009060382843018, 0.8963600993156433, 0.9361830949783325, 0.9515381455421448, 0.9583069682121277, 0.9627581238746643], 'val_loss': [0.4801768362522125, 1.3922181129455566, 1.6072973012924194, 3.020128011703491, 22.318042755126953, 27.096147537231445], 'val_accuracy': [0.8061392307281494, 0.908825159072876, 0.9457336068153381, 0.9380595684051514, 0.940617561340332, 0.955782949924469]}\n"
     ]
    }
   ],
   "source": [
    "#Model eğitiminin başlatılması.\n",
    "\n",
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    train_generator,  \n",
    "    epochs = EPOCHS, \n",
    "    validation_data = val_generator, \n",
    "    verbose = 1,\n",
    "    callbacks = custom_callbacks\n",
    ")\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelin eğitim geçmişinin dosyaya kaydedilmesi.\n",
    "import numpy as np\n",
    "np.save('histories/my_history_CDv2.npy',history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "_4SbABc7jCNX"
   },
   "outputs": [],
   "source": [
    "#Modelin kaydedilmesi.\n",
    "model.save(os.path.join(checkpoint_filepath, 'model_CDv2.h5'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMYpVbf7WVuXJXUzz0ngnb1",
   "collapsed_sections": [],
   "mount_file_id": "16pz1uRVCgdrXyh2fj0s56k5qcp9Zn_1-",
   "name": "NASNetLarge2.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
